# Week 5: Batch Processing

## Setup
here some guide to [install spark on vm](https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/week_5_batch_processing/setup)
there is two markdown to follow, first installing the spark. and the following markdown will install pyspark

## My alternative setup (easy for me)
install anaconda first, if you want to create virtual env you can create it and do the rest of step on it
```
curl -O https://repo.anaconda.com/archive/Anaconda3-2020.07-Linux-x86_64.sh
```
install java 
```
conda install openjdk
```
install pyspark
```
conda install pyspark
```
install findspark
```
conda install -c conda-forge findspark
```
if you have problem with installing pyspark using conda you can using pip to install pyspark. first make sure you have pip installed on your machine
```
sudo apt install pip
```
install pyspark
```
pip install pyspark
```
install findspark 
```
pip install findspark
```
